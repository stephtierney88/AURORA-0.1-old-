import openai
import sounddevice as sd
import numpy as np
import time
from PIL import ImageGrab
import os
import keyboard
import pyautogui
import threading
import sys
import datetime
import requests
from io import BytesIO
from PIL import Image
import schedule
import threading
from tiktoken import Tokenizer

# Parameters
threshold = 0.01  
pause_duration = 1.8  
sampling_rate = 44100  
audio_buffer = []

POWER_WORD = "POWER_WORD"
chat_history = []
CONTEXT_LENGTH = 8192  # or whatever the max token count for GPT-4 is
disable_commands = False  # Global boolean variable to track whether command processing is currently disabled
show_user_text = True
show_ai_text = True
hide_ai_commands = False
hide_user_commands = False
tokenizer = Tokenizer()
token_limit = 5000  # Set this to whatever limit you want
token_counter = 0  # This will keep track of the tokens used so far
character_name = "Aurora"

# Function to run the audio stream
def run_audio_stream():
    with sd.InputStream(callback=audio_callback):
        sd.sleep(1000000)  # This will keep the audio stream open indefinitely. Adjust as needed.





def audio_callback(indata, frames, time, status):
    """Callback to capture audio in real-time."""
    volume_norm = np.linalg.norm(indata) * 10
    if volume_norm < threshold:
        if len(audio_buffer) > sampling_rate * pause_duration:  
            response = openai.Audio.transcribe(
                api_key=API_KEY,
                model="whisper-1",
                file=np.array(audio_buffer)
            )
            
            # Assuming the transcribed text is in `response['text']`
            transcribed_text = response['text']
            
            # Send the transcribed text to ChatGPT
            chatbot_response = send_prompt_to_chatgpt(transcribed_text)
            
            # Process the ChatGPT response
            process_chatgpt_response(chatbot_response)
            
            audio_buffer.clear()  
    else:
        audio_buffer.extend(indata.tolist())


# Start the audio stream in a separate thread
audio_thread = threading.Thread(target=run_audio_stream)
audio_thread.daemon = True
audio_thread.start()

def threshold_check(current_token_count, total_tokens, threshold_percentage):
    threshold = total_tokens * threshold_percentage / 100
    return current_token_count > threshold

def is_command(message):
    return message.startswith(POWER_WORD)

# Function to send prompt to ChatGPT
def send_prompt_to_chatgpt(prompt, image_path=None):
    # Append the timestamp to the prompt
    prompt_with_timestamp = f"{prompt} ~|~|~ {datetime.datetime.now()}"
    
    messages = [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": prompt_with_timestamp}]
    
    # append user message to chat history
    chat_history.append({"role": "user", "content": prompt_with_timestamp})

    if image_path is not None:
        with open(image_path, "rb") as image_file:
            image_data = image_file.read()
        messages.append({"role": "user", "content": {"image": image_data}})
    
    response = openai.ChatCompletion.create(
        model="gpt-4",
        messages=messages,
        max_tokens=100000,
        n=1,
        temperature=0.5,
    )

    # append ChatGPT's response to chat history
    chat_history.append({"role": "assistant", "content": response.choices[0].message['content'].strip()})
    
    # Display the user's text if show_user_text is True
    if show_user_text:
        display_message("user", prompt)

    # Display AI's response based on your visibility settings
    display_message("assistant", response.choices[0].message['content'].strip())
    
    # Count tokens and display
    token_count_message = count_tokens_in_history(chat_history)
    current_token_count = int(token_count_message.split()[0])
    
    # Count tokens and check threshold
    if threshold_check(current_token_count, CONTEXT_LENGTH, 75):
        display_message("system", f"Current token count: {current_token_count} out of {CONTEXT_LENGTH} available")
    
    return response.choices[0].message['content'].strip()


# Define process_chatgpt_response function before calling it

def process_chatgpt_response(response_text):
    handle_commands(response_text, is_user=False)



# Function to handle user input
def user_input_handler():
    global chat_history
    global disable_commands
    while running:
        user_input = input("Type your message, 'recall' to read previous summaries, or 'terminate_instance' to end: ")

        if user_input.startswith('/*'):
            disable_commands = True
            continue  # Skip the rest of the loop
        elif user_input.startswith('*/'):
            disable_commands = False
            continue  # Skip the rest of the loop

        if disable_commands:
            print("Command processing is currently disabled.")
            continue  # Skip the rest of the loop

        # Move all command handling to the handle_commands function
         handle_commands(user_input)

	 response_text = send_prompt_to_chatgpt(user_input)
  	 process_chatgpt_response(response_text)
            if buffer:
                handoff_prompt = buffer[-1]
                response_text = send_prompt_to_chatgpt(handoff_prompt)






def handle_commands(command_input, is_user=True):
    global chat_history
    global disable_commands
    global show_user_text
    global show_ai_text
    global hide_ai_commands
    global hide_user_commands
    
    command_input = f"{command_input}~|~|~{datetime.datetime.now()}"

    if command_input.startswith('/*'):
        disable_commands = True
        return
    elif command_input.startswith('*/'):
        disable_commands = False
        return
    if disable_commands:
        print("Command processing is currently disabled.")
        return 

    # For each possible command, check if it's present in command_input
    # Then execute its corresponding action

    if command_input.startswith("VKB_CMD:"):
        # Strip off the "VKB_CMD:" prefix and split using the delimiter
        command_section, timestamp = command_input[len("VKB_CMD:"):].split("~|~|~")
        commands = command_section.strip().split(';')  # Split multiple commands
        for command in commands:
            command = command.strip()
            if len(command) == 1:
                keyboard.press_and_release(command)
                print(f"Executed command: {command} at {timestamp}")
            else:
                pyautogui.write(command)
                print(f"Typed string: {command} at {timestamp}")

    elif command_input.startswith("CURSORCMD:"):
        command_section = command_input[10:].strip()
        commands = command_section.split(';')  # Split multiple commands
        for command in commands:
            cmd, x, y = command.strip().split(',')
            if cmd == "click":
                pyautogui.click(int(x), int(y))
            elif cmd == "move":
                pyautogui.moveTo(int(x), int(y))
            elif cmd == "right_click":
                pyautogui.rightClick(int(x), int(y))
            print(f"Executed cursor command: {cmd} at ({x}, {y})")

    elif command_input.startswith("HANDOFF"):
        handoff_summary = command_input[7:].strip() 
        buffer.append(handoff_summary)
        timestamp = int(time.time())
        with open(f"{logging_folder}/handoff_{timestamp}.txt", "w") as log_file:
            log_file.write(handoff_summary)
        chat_history.append({'role': 'assistant', 'content': f'Pinned Handoff context: {handoff_summary}'})
        all_entries = [f"{entry['role']}: {entry['content']}" for entry in chat_history]
        write_content_to_file("\n".join(all_entries), "all_entries.txt")
        print("Handoff summary saved.")
        restart_chatgpt_instance()

    elif command_input.startswith("PIN"):
        exemption_context = command_input[4:].strip()
        chat_history.append({'role': 'assistant', 'content': f'Exemption: {exemption_context}'})
        print(f"Exemption pinned: {exemption_context}")

    elif command_input.startswith("SHUTDOWN_EXIT_INSTANCE"):
        shutdown_chatgpt_instance_and_exit()

    elif command_input.startswith('TERMINATE_INSTANCE'):
        terminate_instance()

    elif command_input.startswith("RECALL"):
        recall_previous_summary(character_name)
    
    elif command_input.startswith('INIT'):
        # Remove any previous Pinned Init summary
        chat_history = [entry for entry in chat_history if not entry['content'].startswith('Pinned Init summary')]

        # Add new Pinned Init summary
        init_summary = command_input[5:]
        chat_history.append({'role': 'user', 'content': f'Pinned Init summary: {init_summary}'})
        print(f"Pinned Init summary: {init_summary}")

    elif command_input.startswith('RETRIEVE_HANDOFF'):
        # This assumes that the handoff filename will be provided in the format: 'Retrieve_HANDOFF_filename.txt'
        handoff_filename = command_input.split('_')[2].strip()
        if not handoff_filename:
            print("No handoff file specified.")
            return
    
        handoff_filepath = f"{logging_folder}/{handoff_filename}"
        if not os.path.exists(handoff_filepath):
            print(f"No such file exists: {handoff_filepath}")
            return
    
        with open(handoff_filepath, "r") as file:
            handoff_summary = file.read().strip()
    
        # Check if this handoff summary is already in the chat history
        if any(entry['content'].startswith(f'Pinned Handoff context: {handoff_summary}') for entry in chat_history):
            print("Handoff summary already in chat history.")
            return
    
        # If not, add the summary to the chat history
        chat_history.append({'role': 'assistant', 'content': f'Pinned Handoff context: {handoff_summary}'})
        print(f"Pinned Handoff context from file: {handoff_summary}")

    elif command_input.startswith("CLEAR_NON_PINNED"):
        # Keep only the Pinned Init summary, Pinned Handoff context and Exemptions
        chat_history = [entry for entry in chat_history if entry['content'].startswith('Pinned Init summary') or entry['content'].startswith('Pinned Handoff context') or entry['content'].startswith('Exemption')]
        print("Chat history cleared, only pinned summaries and exemptions remain.")

    elif command_input.startswith("CLEAR%"):
        # Extract the percentage value from the command
        try:
            percentage_to_clear = float(command_input[6:].strip()) / 100
            if 0 <= percentage_to_clear <= 1:
                clear_chat_history(percentage_to_clear)
            else:
                print("Invalid percentage. Please enter a number between 0 and 100.")
        except ValueError:
            print("Invalid command format. Expected format is 'CLEAR%{number}'.")

    elif command_input.startswith("CLEARALL"):
        # Keep only the Pinned Init summary and Pinned Handoff context
        chat_history = [entry for entry in chat_history if entry['content'].startswith('Pinned Init summary') or entry['content'].startswith('Pinned Handoff context')]
        print("Chat history cleared, only pinned summaries remain.")

    elif command_input.startswith('SAVEPINNEDINIT'):
        pinned_init_summaries = [entry['content'][19:] for entry in chat_history if entry['content'].startswith('Pinned Init summary')]
        write_content_to_file("\n".join(pinned_init_summaries), "pinned_init_summaries.txt")

    elif command_input.startswith('SAVEPINNEDHANDOFF'):
        pinned_handoff_contexts = [entry['content'][22:] for entry in chat_history if entry['content'].startswith('Pinned Handoff context')]
        write_content_to_file("\n".join(pinned_handoff_contexts), "pinned_handoff_contexts.txt")

    elif command_input.startswith('SAVEEXEMPTIONS'):
        exemptions = [entry['content'][10:] for entry in chat_history if entry['content'].startswith('Exemption')]
        write_content_to_file("\n".join(exemptions), "exemptions.txt")

    elif command_input.startswith('SAVEPINNED'):
        pinned_entries = [entry['content'] for entry in chat_history if entry['content'].startswith('Pinned Init summary') or entry['content'].startswith('Pinned Handoff context')]
        write_content_to_file("\n".join(pinned_entries), "pinned_entries.txt")

    elif command_input.startswith('SAVEALL'):
        all_entries = [f"{entry['role']}: {entry['content']}" for entry in chat_history]
        write_content_to_file("\n".join(all_entries), "all_entries.txt")

    elif command_input == 'HELP_VISIBILITY':
        display_message("system", """
        HIDE - Toggle the visibility of user text.
        HIDE_AI - Toggle the visibility of AI responses.
        HIDE_AI_COMMANDS - Toggle the visibility of commands given by the AI.
        HIDE_USER_COMMANDS - Toggle the visibility of commands issued by the user.
    """)

    elif command_input == 'HIDE':
        show_user_text = not show_user_text
        if show_user_text:
            display_message("system", "User text will now be displayed.")
        else:
            display_message("system", "User text will now be hidden.")

    elif command_input == 'HIDE_AI':
        show_ai_text = not show_ai_text
        if show_ai_text:
            display_message("system", "AI text will now be displayed.")
        else:
            display_message("system", "AI text will now be hidden.")

    elif command_input == 'HIDE_AI_COMMANDS':
        hide_ai_commands = not hide_ai_commands
        if hide_ai_commands:
            display_message("system", "AI commands will now be hidden.")
        else:
            display_message("system", "AI commands will now be displayed.")

elif command_input == 'HIDE_USER_COMMANDS':
    hide_user_commands = not hide_user_commands
    if hide_user_commands:
        display_message("system", "User commands will now be hidden.")
    else:
        display_message("system", "User commands will now be displayed.")

else:
    # If none of the commands match
    # Use the new display function for the AI's text
    role = "assistant" if not is_user else "user"
    if not (is_user and hide_user_commands) or (not is_user and hide_ai_commands):
        display_message(role, command_input)
        chat_history.append({"role": role, "content": command_input})

    token_count = count_tokens_in_history(chat_history)
    tokens_in_message = len(list(tokenizer.tokenize(command_input)))
    token_counter += tokens_in_message
    save_chat_history_to_file()
    print(f"Current token count in chat history: {token_count}")




def write_content_to_file(content, file_name):
        with open(file_name, "w") as f:
            f.write(content)
        print(f"Content saved to {file_name}")

def initiate_and_handoff():
    response_text = send_prompt_to_chatgpt(init_prompt)
    process_chatgpt_response(response_text)
    if buffer:
        handoff_prompt = buffer[-1]
        response_text = send_prompt_to_chatgpt(handoff_prompt)


# Define clear_chat_history function with percentage
def clear_chat_history(percentage):
    global chat_history

    with chat_history_lock:
        # Number of chats to keep
        num_chats_to_keep = int(len(chat_history) * (1-percentage))

        pinned_entries = [entry for entry in chat_history if entry['content'].startswith('Pinned Init summary') or entry['content'].startswith('Pinned Handoff context')]
        exempted_entries = [entry for entry in chat_history if entry['content'].startswith('Exemption')]

        # Concatenate the lists and sort them by their index in the original chat_history
        exempted_and_pinned_entries = sorted(pinned_entries + exempted_entries, key=chat_history.index)

        # If the number of chats to keep is less than the length of the exempted_and_pinned_entries list
        # Keep only the most recent exempted and pinned entries
        if num_chats_to_keep < len(exempted_and_pinned_entries):
            chat_history = exempted_and_pinned_entries[-num_chats_to_keep:]
        else:
            non_exempted_entries = [entry for entry in chat_history if entry not in exempted_and_pinned_entries]
            chat_history = non_exempted_entries[-(num_chats_to_keep-len(exempted_and_pinned_entries)):] + exempted_and_pinned_entries
            
        print(f"Chat history cleared, {int(percentage*100)}% chats are removed, only most recent {num_chats_to_keep} entries, pinned summaries, and exemptions remain.")




# Function to check if daily summary has been completed
def daily_summary_completed(date):
    filename = f"{logging_folder}/daily_summary_{date}.txt"
    return os.path.exists(filename)

# Function to save daily summary
def save_daily_summary():
    date = datetime.date.today().strftime("%Y-%m-%d")
    if not daily_summary_completed(date):
        summary_prompt = "Summarize the important events and points from Aurora's perspective today."
        daily_summary_text = send_prompt_to_chatgpt(summary_prompt)
        with open(f"{logging_folder}/daily_summary_{date}.txt", "w") as log_file:
            log_file.write(daily_summary_text)
        print("Daily summary saved.")

# Function to check if it's time to save the daily summary
def check_daily_summary_time():
    current_time = datetime.datetime.now().time()
    daily_summary_time = datetime.time(hour=19)  # 7 PM
    return current_time >= daily_summary_time

def daily_summary():
    current_time = datetime.datetime.now()
    if current_time.hour == 19:  # 7 pm
        summary = send_prompt_to_chatgpt("Summarize today's important events and points from Aurora's perspective.")
        process_chatgpt_response(summary)
        with open(f"{logging_folder}/daily_summary_{current_time.strftime('%Y-%m-%d')}.txt", "w") as log_file:
            log_file.write(summary)
        print("Daily summary saved.")

# Function to check for handoff from previous day
def check_previous_handoff():
    today = datetime.date.today()
    yesterday = today - datetime.timedelta(days=1)
    handoff_filename = f"{logging_folder}/handoff_{yesterday.strftime('%Y-%m-%d')}.txt"
    if os.path.exists(handoff_filename):
        with open(handoff_filename, "r") as handoff_file:
            handoff_text = handoff_file.read()
        response_text = send_prompt_to_chatgpt(handoff_text)
        process_chatgpt_response(response_text)

# Function to perform shutdown procedure for the current ChatGPT instance and exit the program
def shutdown_chatgpt_instance_and_exit():
    global running
    date = datetime.date.today().strftime("%Y-%m-%d")
    if not daily_summary_completed(date):
        save_daily_summary()
    handoff_summary = f"Handoff {date}: " + buffer[-1]  # Save the last summary in the buffer
    with open(f"{logging_folder}/handoff_{date}.txt", "w") as log_file:
        log_file.write(handoff_summary)
    print("Handoff summary saved.")
    # Exit the program
    print("Exiting the program.")
    sys.exit()

def terminate_instance():
    daily_summary()
    handoff_summary = send_prompt_to_chatgpt("Create a handoff summary for the next instance.")
    process_chatgpt_response(handoff_summary)
    with open(f"{logging_folder}/Handoff_{datetime.datetime.now().strftime('%Y-%m-%d')}.txt", "w") as log_file:
        log_file.write(handoff_summary)
    print("Handoff summary saved.")
    # You can use sys.exit() to exit the program
    sys.exit()


# Function to restart ChatGPT instance
def restart_chatgpt_instance():
    # Send init_prompt and handoff_prompt to the new instance
    response_text = send_prompt_to_chatgpt(init_prompt)
    process_chatgpt_response(response_text)
    if buffer:
        handoff_prompt = buffer[-1]
        response_text = send_prompt_to_chatgpt(handoff_prompt)
    
    # Send init_prompt and handoff_prompt to the new instance
    response_text = send_prompt_to_chatgpt(init_prompt)
  

def check_for_previous_handoff():
    today = datetime.datetime.now().date()
    yesterday = today - datetime.timedelta(days=1)
    handoff_filename = f"{logging_folder}/Handoff_{yesterday.strftime('%Y-%m-%d')}.txt"
    if os.path.exists(handoff_filename):
        with open(handoff_filename, "r") as handoff_file:
            handoff_text = handoff_file.read()
        response_text = send_prompt_to_chatgpt(handoff_text)
        process_chatgpt_response(response_text)


def recall_previous_summary(character_name):
    today = datetime.date.today()
    yesterday = today - datetime.timedelta(days=1)
    handoff_file = f"{logging_folder}/handoff_{yesterday.strftime('%Y-%m-%d')}.txt"
    
    if os.path.exists(handoff_file):
        with open(handoff_file, "r") as f:
            handoff_text = f.read().strip()
        print("Handoff summary:", handoff_text)
    else:
        print("No handoff summary found for the previous day.")
    
    init_file = f"{character_name}_init.txt"
    if os.path.exists(init_file):
        with open(init_file, "r") as f:
            init_text = f.read().strip()
        print("Initial profile summary:", init_text)
    else:
        print("No initial profile summary found.")



# Function to take a screenshot
def take_screenshot():
    if screenshot_options["current_window"]:
        # Code to capture the current window snapshot
        # Depending on the platform, you might need additional libraries and code
        pass

    if screenshot_options["entire_screen"]:
        # Capture entire screen
        screenshot = ImageGrab.grab()
        timestamp = int(time.time())
        screenshot_file_path = f"{logging_folder}/{timestamp}.png"
        screenshot.save(screenshot_file_path)
        send_prompt_to_chatgpt("Here is a screenshot:", screenshot_file_path)


# Function to run the scheduled tasks
def run_scheduled_tasks():
    while running:
        schedule.run_pending()
        time.sleep(1)

# Read the init prompt from a file
init_file = f"{character_name}_init.txt"
with open(init_file, "r") as f:
    init_prompt = f.read().strip()



# Read the handoff summary from a file
handoff_file = f"{character_name}_handoff.txt"
if os.path.exists(handoff_file):
    with open(handoff_file, "r") as f:
        handoff_text = f.read().strip()
    response_text = send_prompt_to_chatgpt(handoff_text)
    process_chatgpt_response(response_text)

# Global variable to control the main loop
running = True

# Set up OpenAI API client
openai.api_key = "API KEY HERE"

# Initialize ChatGPT API endpoint
endpoint_url = "https://api.openai.com/v1/chat/completions/gpt-4"

# Time interval between screenshots (in seconds)
time_interval = 25.5

# Set up screenshot options
screenshot_options = {
    "current_window": True,
    "entire_screen": True,
}

# Set up buffer and logging folder
buffer = []
logging_folder = "screenshots"
if not os.path.exists(logging_folder):
    os.makedirs(logging_folder)



# Send init prompt to ChatGPT
response_text = send_prompt_to_chatgpt(init_prompt)
print("ChatGPT response:", response_text)




initiate_and_handoff()



# Create a thread for user input handling and start it
#user_input_thread = threading.Thread(target=lambda: user_input_handler(input("Type your message, 'recall' to read previous summaries, or 'terminate_instance' to end: ")))
user_input_thread = threading.Thread(target=user_input_handler)
user_input_thread.daemon = True
user_input_thread.start()


# Schedule the screenshot taking function
schedule.every(time_interval).seconds.do(take_screenshot)

# Schedule daily summary
schedule.every().day.at("19:00").do(save_daily_summary)

# Create a thread for running scheduled tasks and start it
scheduled_tasks_thread = threading.Thread(target=run_scheduled_tasks)
scheduled_tasks_thread.daemon = True
scheduled_tasks_thread.start()

# Main loop to keep the program running
while running:
    pass
